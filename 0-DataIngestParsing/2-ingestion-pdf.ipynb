{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69dc89fe",
   "metadata": {},
   "source": [
    "# Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e391f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import(\n",
    "PyPDFLoader,\n",
    "PyMuPDFLoader,\n",
    "UnstructuredPDFLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyPDFLoader\n",
    "# used for standard text and PDFs\n",
    "# page number preserved, basic text extraction may not work.\n",
    "\n",
    "try:\n",
    "    pypdf_loader = PyPDFLoader(\"data/pdf/attention.pdf\")\n",
    "    pypdf_docs = pypdf_loader.load()\n",
    "   # print(pypdf_docs)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"error :{e}\")\n",
    "\n",
    "\n",
    "print(f\"pages {len(pypdf_docs)}\\n\")\n",
    "print(f\"metadata {pypdf_docs[0].metadata} \\n\")\n",
    "print(f\"content {pypdf_docs[0].page_content[:100]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyMuPDFLoader\n",
    "# more fast\n",
    "# image and text extraction supported\n",
    "\n",
    "try:\n",
    "    pypdf_loader = PyMuPDFLoader(\"data/pdf/attention.pdf\")\n",
    "    pypdf_docs = pypdf_loader.load()\n",
    "   # print(pypdf_docs)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"error :{e}\")\n",
    "\n",
    "print(f\"pages {len(pypdf_docs)}\\n\")\n",
    "print(f\"metadata {pypdf_docs[0].metadata} \\n\")\n",
    "print(f\"content {pypdf_docs[0].page_content[:100]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e444d",
   "metadata": {},
   "source": [
    "# Reading Complex PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_text = \"\"\"Company Financial Report\n",
    "\n",
    "\n",
    "    The ﬁnancial performance for ﬁscal year 2024\n",
    "    shows signiﬁcant growth in proﬁtability.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Revenue increased by 25%.\n",
    "    \n",
    "The company's efﬁciency improved due to workﬂow\n",
    "optimization.\n",
    "\n",
    "\n",
    "Page 1 of 10\n",
    "\"\"\"\n",
    "\n",
    "# Apply a clean function\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove excessive whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Fix ligatures\n",
    "    text = text.replace(\"ﬁ\", \"fi\")\n",
    "    text = text.replace(\"ﬂ\", \"fl\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"before :\\n\",\"-\"*10)\n",
    "print(raw_pdf_text[0:100])\n",
    "print(\"after :\\n\",\"-\"*10)\n",
    "cleaned = clean_text(raw_pdf_text)\n",
    "print(cleaned[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f535caa",
   "metadata": {},
   "source": [
    "# PDF Processor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f15157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This smart processor load the PDF, read texts, clean the text, add the meta data and return the list of Document\n",
    "\n",
    "class SmartPDFProcessor:\n",
    "    \"\"\"Advanced PDF processing with error handling\"\"\"\n",
    "    def __init__(self, chunk_size=1000,chunk_overlap=100):\n",
    "        self.chunk_size= chunk_size\n",
    "        self.chunk_overlap= chunk_overlap\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "          chunk_size = chunk_size,\n",
    "          chunk_overlap = chunk_overlap,\n",
    "          separators=[\" \"]  \n",
    "        )\n",
    "\n",
    "    def process_pdf(self, pdf_path:str) -> List[Document]:\n",
    "      \"\"\"Process PDF with smart chunking and metadata enhancement\"\"\"\n",
    "\n",
    "      #load pdf\n",
    "      loader = PyPDFLoader(pdf_path)\n",
    "      pages = loader.load()\n",
    "\n",
    "      processed_chunks = []\n",
    "\n",
    "      for page_num, page in enumerate(pages):\n",
    "        cleaned_text = self._clean_text(page.page_content)\n",
    "\n",
    "        if len(cleaned_text.strip()) < 50:\n",
    "           continue\n",
    "        \n",
    "        chunks = self.text_splitter.create_documents(\n",
    "           texts=[cleaned_text],\n",
    "           metadatas=[{\n",
    "             \"page\":page_num+1,\n",
    "             \"total_page\":len(pages),\n",
    "             \"chunk_method\":\"smart_pdf_processor\",\n",
    "             \"char_count\":len(cleaned_text)\n",
    "           }]\n",
    "        )\n",
    "\n",
    "        processed_chunks.extend(chunks)\n",
    "\n",
    "      return processed_chunks\n",
    "    \n",
    "    def _clean_text(self, text :str)-> str:\n",
    "       text = \" \".join(text.split())\n",
    "\n",
    "       text = text.replace(\"ﬁ\", \"fi\")\n",
    "       text = text.replace(\"ﬂ\", \"fl\")\n",
    "    \n",
    "       return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87151b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use smartPDFProcessor\n",
    "preprocessor = SmartPDFProcessor()\n",
    "preprocessor\n",
    "\n",
    "try:\n",
    "    chunked_docs = preprocessor.process_pdf(\"data/pdf/attention.pdf\")\n",
    "    print(f\"processed into {len(chunked_docs)} smart chunk\")\n",
    "\n",
    "    if chunked_docs:\n",
    "        chunk=chunked_docs[0]\n",
    "        print(f\"metadata of first item:\\n {chunk.metadata}\")\n",
    "        print(f\"content of first item:\\n {chunk.page_content}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"processing error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
